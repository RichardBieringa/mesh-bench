{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pathlib\n",
    "import json\n",
    "from typing import List, TypedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root of the project\n",
    "project_dir = pathlib.Path().resolve().parent\n",
    "\n",
    "# Directory containing experiment results\n",
    "results_dir = (pathlib.Path(project_dir) / \"results\").resolve()\n",
    "\n",
    "# Directory for tidied data (output directory)\n",
    "data_dir = (pathlib.Path(project_dir) / \"data\").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represents a single data point of system utilization\n",
    "class ResourceResult(TypedDict):\n",
    "    experiment: str\n",
    "    mesh: str\n",
    "    qps: str\n",
    "    pod: str\n",
    "    container: str\n",
    "    time: int\n",
    "    cpu: float\n",
    "    mem: float\n",
    "\n",
    "\n",
    "def parse_resource_result(result_file: pathlib.Path) -> List[ResourceResult]:\n",
    "    \"\"\" Reads a result file and parses the data.\n",
    "\n",
    "    The returned data is a list of ResourceResults that represent a\n",
    "    single metric over a time span of 15 minutes.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    # Regex to extra# 0 -> Full match\n",
    "    # 1 -> mem/cpu results\n",
    "    # 2 -> Mesh\n",
    "    # 3 -> Requested QPS\n",
    "    name_re = re.compile(\"^(mem|cpu)_([a-z]+)_(\\d+|MAX).*json$\")\n",
    "\n",
    "    # Extract metadata from the result\n",
    "    matches = name_re.match(result_file.name)\n",
    "\n",
    "    experiment = result_file.parent.name\n",
    "    metric = matches[1]\n",
    "    mesh = matches[2].capitalize()\n",
    "    qps = matches[3]\n",
    "\n",
    "    with open(result_file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # The resutl is lister per pod/container\n",
    "    for container in data:\n",
    "\n",
    "        # Metadata (dimensions)\n",
    "        meta = container[\"metric\"]\n",
    "\n",
    "        # Actual values in list[unixtime, value]\n",
    "        values = container[\"values\"]\n",
    "\n",
    "        for v in values:\n",
    "            row: ResourceResult = {\n",
    "                \"experiment\": experiment,\n",
    "                \"mesh\": mesh,\n",
    "                \"requested_qps\": qps,\n",
    "                \"pod\": meta[\"pod\"],\n",
    "                \"container\": meta[\"container\"],\n",
    "                \"time\": v[0],\n",
    "                metric: v[1],\n",
    "            }\n",
    "            rows.append(row)\n",
    "\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Clean the obtained results from the experiments\n",
    "- Remove unnecessary columns\n",
    "- Extract metadata from filenames\n",
    "- Construct and clean data into a pandas.Series object\n",
    "- Convert data measures in seconds to ms\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Represents a binned data point of a fortio result file\n",
    "class FortioObservation(TypedDict):\n",
    "    # Dimensions\n",
    "    experiment: str\n",
    "    mesh: str\n",
    "    requested_qps: str\n",
    "    protocol: str\n",
    "    payload: int\n",
    "\n",
    "    # Variables\n",
    "    actual_qps: str\n",
    "    latency: float\n",
    "\n",
    "\n",
    "def parse_fortio_result(result_file: pathlib.Path) -> List[FortioObservation] :\n",
    "    \"\"\"\n",
    "    Reads a fortio results JSON file, cleans the data and returns\n",
    "    it as a pandas.Series\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # fortio reports in seconds, convert to miliseconds\n",
    "    multiplier = 1000\n",
    "\n",
    "    # Regex to extract metadata\n",
    "    # 0 -> Full match\n",
    "    # 1 -> Protocol (http/grpc)\n",
    "    # 2 -> Mesh\n",
    "    # 3 -> Requested QPS\n",
    "    # 4 -> Transfer in bytes\n",
    "    # 5 -> Repetitionct dimensions from the filename\n",
    "    name_re = re.compile(\"^([a-z]+)_([a-z]+)_(\\d+|MAX)_(\\d+)_(\\d+).*json$\")\n",
    "\n",
    "\n",
    "    # Extract metadata from the result\n",
    "    matches = name_re.match(result_file.name)\n",
    "\n",
    "    with open(result_file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    if \"Error\" in data:\n",
    "        raise ValueError(f\"{result_file.name} contains an error: {data['Error']}\")\n",
    "    \n",
    "    sample_arrays = []\n",
    "    for d in data[\"DurationHistogram\"][\"Data\"]:\n",
    "        low = d[\"Start\"] * multiplier\n",
    "        high = d[\"End\"] * multiplier\n",
    "        size = d[\"Count\"]\n",
    "        sample_arrays.append(np.random.uniform(low=low, high=high, size=size))\n",
    "\n",
    "    samples = np.concatenate(sample_arrays)\n",
    "\n",
    "    obs: FortioObservation = {\n",
    "        \"experiment\": result_file.parent.name,\n",
    "        \"mesh\": matches[2].capitalize(),\n",
    "        \"requested_qps\": matches[3],\n",
    "        \"protocol\": matches[1],\n",
    "        \"payload\": matches[4],\n",
    "        \"actual_qps\": data[\"ActualQPS\"],\n",
    "        \"latency\": samples,\n",
    "    }\n",
    "\n",
    "    results.append(obs)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing experiment: 02_http_constant_throughput\n",
      "Processing experiment: 01_http_max_throughput\n",
      "Processing experiment: 04_grpc_max_throughput\n",
      "grpc_traefik_MAX_0_1_2022-06-27T11:13:12Z.json contains an error: Aborting because of error\n",
      "Processing experiment: 03_http_payload\n"
     ]
    }
   ],
   "source": [
    "# Get all experiments directories (filters out old data)\n",
    "experiment_dir_re = re.compile(\"^\\d{2}_([a-zA-Z_])+$\")\n",
    "experiment_dirs = [x for x in results_dir.iterdir() if x.is_dir() and re.match(experiment_dir_re, x.name)]\n",
    "\n",
    "result_re = re.compile(\"^(cpu|mem|http|grpc)_(\\w+)_(\\d+|MAX).*\\.json$\")\n",
    "\n",
    "# Contains the two types of results\n",
    "results = {\n",
    "    \"fortio\": [],\n",
    "    \"resource\": [],\n",
    "}\n",
    "\n",
    "for d in experiment_dirs:\n",
    "    print(f\"Processing experiment: {d.name}\")\n",
    "\n",
    "    files = d.glob(\"*.json\")\n",
    "    for f in files:\n",
    "        matches = result_re.match(f.name)\n",
    "\n",
    "        if matches is None:\n",
    "            raise ValueError(f\"Invalid file: {f.name}\")\n",
    "        \n",
    "        result_type = matches[1]\n",
    "\n",
    "        # Parse result files\n",
    "        try:\n",
    "            if result_type == \"cpu\" or result_type == \"mem\":\n",
    "                results[\"resource\"].extend(parse_resource_result(f))\n",
    "            elif result_type == \"http\" or result_type == \"grpc\":\n",
    "                results[\"fortio\"].extend(parse_fortio_result(f))\n",
    "        except ValueError as err:\n",
    "            print(err)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>mesh</th>\n",
       "      <th>requested_qps</th>\n",
       "      <th>pod</th>\n",
       "      <th>container</th>\n",
       "      <th>cpu</th>\n",
       "      <th>mem</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01_http_max_throughput</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>MAX</td>\n",
       "      <td>target-fortio-746f85d498-tmrfm</td>\n",
       "      <td>fortio</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>1072.776342</td>\n",
       "      <td>2022-06-26 14:31:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_http_max_throughput</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>MAX</td>\n",
       "      <td>target-fortio-746f85d498-tmrfm</td>\n",
       "      <td>fortio</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>1072.776342</td>\n",
       "      <td>2022-06-26 14:32:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01_http_max_throughput</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>MAX</td>\n",
       "      <td>target-fortio-746f85d498-tmrfm</td>\n",
       "      <td>fortio</td>\n",
       "      <td>0.049509</td>\n",
       "      <td>18820.872955</td>\n",
       "      <td>2022-06-26 14:32:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01_http_max_throughput</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>MAX</td>\n",
       "      <td>target-fortio-746f85d498-tmrfm</td>\n",
       "      <td>fortio</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>24103.189715</td>\n",
       "      <td>2022-06-26 14:32:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01_http_max_throughput</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>MAX</td>\n",
       "      <td>target-fortio-746f85d498-tmrfm</td>\n",
       "      <td>fortio</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>24103.189715</td>\n",
       "      <td>2022-06-26 14:32:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               experiment      mesh requested_qps  \\\n",
       "0  01_http_max_throughput  Baseline           MAX   \n",
       "1  01_http_max_throughput  Baseline           MAX   \n",
       "2  01_http_max_throughput  Baseline           MAX   \n",
       "3  01_http_max_throughput  Baseline           MAX   \n",
       "4  01_http_max_throughput  Baseline           MAX   \n",
       "\n",
       "                              pod container       cpu           mem  \\\n",
       "0  target-fortio-746f85d498-tmrfm    fortio  0.000719   1072.776342   \n",
       "1  target-fortio-746f85d498-tmrfm    fortio  0.000719   1072.776342   \n",
       "2  target-fortio-746f85d498-tmrfm    fortio  0.049509  18820.872955   \n",
       "3  target-fortio-746f85d498-tmrfm    fortio  0.063200  24103.189715   \n",
       "4  target-fortio-746f85d498-tmrfm    fortio  0.063200  24103.189715   \n",
       "\n",
       "                 date  \n",
       "0 2022-06-26 14:31:58  \n",
       "1 2022-06-26 14:32:01  \n",
       "2 2022-06-26 14:32:04  \n",
       "3 2022-06-26 14:32:07  \n",
       "4 2022-06-26 14:32:10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Create a pandas DataFrame for resource results\n",
    "- Each row represents a single observation\n",
    "- Each observation takes a form of type ResourceResult\n",
    "- Rows are merged based on time/pod/container -> this halves rows as both CPU/mem metrics share unix timestamps\n",
    "- Convert unix timestamps to pd.DateTime\n",
    "\"\"\"\n",
    "\n",
    "# Initial dataset\n",
    "resource_df = pd.DataFrame(data=results[\"resource\"])\n",
    "\n",
    "# Merged CPU/mem results\n",
    "resource_df = resource_df.groupby(by=[\"experiment\", \"mesh\", \"requested_qps\", \"pod\", \"container\", \"time\"], as_index=False).first()\n",
    "\n",
    "# Convert time column to datetime\n",
    "resource_df[\"date\"] = pd.to_datetime(resource_df[\"time\"],unit=\"s\")\n",
    "resource_df[\"cpu\"] = pd.to_numeric(resource_df[\"cpu\"])\n",
    "resource_df[\"mem\"] = pd.to_numeric(resource_df[\"mem\"])\n",
    "\n",
    "resource_df = resource_df.drop(\"time\", axis=1)\n",
    "\n",
    "resource_df.to_csv(data_dir / \"resource_results.feather\")\n",
    "resource_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>mesh</th>\n",
       "      <th>requested_qps</th>\n",
       "      <th>protocol</th>\n",
       "      <th>payload</th>\n",
       "      <th>actual_qps</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02_http_constant_throughput</td>\n",
       "      <td>Traefik</td>\n",
       "      <td>500</td>\n",
       "      <td>http</td>\n",
       "      <td>0</td>\n",
       "      <td>419.003821</td>\n",
       "      <td>[0.3885955809167401, 0.35178629357734, 0.39257...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02_http_constant_throughput</td>\n",
       "      <td>Istio</td>\n",
       "      <td>1</td>\n",
       "      <td>http</td>\n",
       "      <td>0</td>\n",
       "      <td>0.966557</td>\n",
       "      <td>[0.8516197639315487, 0.8741539395657092, 0.871...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02_http_constant_throughput</td>\n",
       "      <td>Linkerd</td>\n",
       "      <td>100</td>\n",
       "      <td>http</td>\n",
       "      <td>0</td>\n",
       "      <td>99.965385</td>\n",
       "      <td>[0.28963468661425174, 0.28852236048631275, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02_http_constant_throughput</td>\n",
       "      <td>Linkerd</td>\n",
       "      <td>1000</td>\n",
       "      <td>http</td>\n",
       "      <td>0</td>\n",
       "      <td>994.641782</td>\n",
       "      <td>[0.18606631408045254, 0.1841971223829685, 0.19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02_http_constant_throughput</td>\n",
       "      <td>Cilium</td>\n",
       "      <td>500</td>\n",
       "      <td>http</td>\n",
       "      <td>0</td>\n",
       "      <td>499.000306</td>\n",
       "      <td>[0.17054266850987035, 0.17150125866605476, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    experiment     mesh requested_qps protocol payload  \\\n",
       "0  02_http_constant_throughput  Traefik           500     http       0   \n",
       "1  02_http_constant_throughput    Istio             1     http       0   \n",
       "2  02_http_constant_throughput  Linkerd           100     http       0   \n",
       "3  02_http_constant_throughput  Linkerd          1000     http       0   \n",
       "4  02_http_constant_throughput   Cilium           500     http       0   \n",
       "\n",
       "   actual_qps                                            latency  \n",
       "0  419.003821  [0.3885955809167401, 0.35178629357734, 0.39257...  \n",
       "1    0.966557  [0.8516197639315487, 0.8741539395657092, 0.871...  \n",
       "2   99.965385  [0.28963468661425174, 0.28852236048631275, 0.2...  \n",
       "3  994.641782  [0.18606631408045254, 0.1841971223829685, 0.19...  \n",
       "4  499.000306  [0.17054266850987035, 0.17150125866605476, 0.1...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Create a pandas DataFrame for fortio results\n",
    "- Each row represents a binned observation\n",
    "\"\"\"\n",
    "\n",
    "fortio_df = pd.DataFrame(data=results[\"fortio\"])\n",
    "fortio_df.to_feather(data_dir / \"fortio_results.feather\")\n",
    "fortio_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
